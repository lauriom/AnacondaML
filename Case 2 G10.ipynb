{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case X.\n",
    "Lauri Marjanen, Team 10<br>\n",
    "Neural Networks for Machine Learning Applications<br>\n",
    "[Helsinki Metropolia University of Applied Sciences](http://www.metropolia.fi/en/)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "tensorflow 2.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Anaconda ML\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['hist', 'copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "%pylab inline\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this Notebook is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Different data processing methods attempted:\n",
    "set image color = grayscale to change image dim from 128*128*3 to 128*128*1, did not help accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Using 4173 files for training.\n",
      "Found 5216 files belonging to 2 classes.\n",
      "Using 1043 files for validation.\n",
      "Found 624 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "curDir = os.getcwd()\n",
    "train_dir = curDir + '/input/train'\n",
    "test_dir = curDir + '/input/test'\n",
    "val_dir = curDir + '/input/val'\n",
    "\n",
    "# Training dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split = 0.2,\n",
    "  subset = \"training\",\n",
    "  seed = 123,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "\n",
    "# Validation dataset\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  validation_split = 0.2,\n",
    "  subset = \"validation\",\n",
    "  seed = 123,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  image_size = (img_height, img_width),\n",
    "  batch_size = batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n",
      "Found 1043 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator( # Usually xray machines force you to stand still in a specific position,\n",
    "                              # so it does not make sense for the data to be augmented too much\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.11,\n",
    "  zoom_range=0.11,\n",
    "  fill_mode='nearest',\n",
    "  validation_split=0.2\n",
    ")\n",
    "train_gen_ds = datagen.flow_from_directory(train_dir, class_mode='binary',\n",
    "                                         subset = \"training\",\n",
    "                                         target_size = (img_height, img_width),\n",
    "                                         batch_size = batch_size)\n",
    "val_gen_ds = datagen.flow_from_directory(train_dir, class_mode='binary',\n",
    "                                         subset = \"validation\",\n",
    "                                         target_size = (img_height, img_width),\n",
    "                                         batch_size = batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model was used: \"vanilla\" 2d image model, 2d image model with generated data,\n",
    "pretrained model with a normal data , and pretrained model with generated image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_6 (Rescaling)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d_394 (Conv2D)         (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 64, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_395 (Conv2D)         (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_396 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               8388736   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,412,449\n",
      "Trainable params: 8,412,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_6 (Rescaling)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d_394 (Conv2D)         (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 64, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_395 (Conv2D)         (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_396 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               8388736   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,412,449\n",
      "Trainable params: 8,412,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16,3, padding='same', activation= 'relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32,3, padding='same', activation= 'relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64,3, padding='same', activation= 'relu'),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = optimizers.RMSprop(learning_rate= 1e-4),\n",
    "              metrics= ['accuracy'])\n",
    "\n",
    "gen_model = keras.models.clone_model(model)\n",
    "gen_model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = optimizers.RMSprop(learning_rate= 1e-4),\n",
    "              metrics= ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "gen_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_10  (None, 128, 128, 3)      0         \n",
      "  (SlicingOpLambda)                                              \n",
      "                                                                 \n",
      " tf.nn.bias_add_10 (TFOpLamb  (None, 128, 128, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 2, 2, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,804,833\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_10  (None, 128, 128, 3)      0         \n",
      "  (SlicingOpLambda)                                              \n",
      "                                                                 \n",
      " tf.nn.bias_add_10 (TFOpLamb  (None, 128, 128, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 2, 2, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,804,833\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "preprocess_input = tf.keras.applications.resnet.preprocess_input\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(input_shape=(img_width,img_height,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "#Modeling the child\n",
    "\n",
    "inputs = tf.keras.Input(shape = (img_width, img_height,3))\n",
    "holder = preprocess_input(inputs)\n",
    "holder = base_model(holder, training = False)\n",
    "holder = global_average_layer(holder)\n",
    "holder = tf.keras.layers.Dropout(0.2)(holder)\n",
    "outputs = prediction_layer(holder)\n",
    "pre_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "pre_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "pre_gen_model = keras.models.clone_model(pre_model)\n",
    "pre_gen_model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = optimizers.RMSprop(learning_rate= 1e-4),\n",
    "              metrics= ['accuracy'])\n",
    "\n",
    "pre_model.summary()\n",
    "pre_gen_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results were achieved ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "EPOCHS = 4\n",
    "VERBOSE = 0\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "hist = model.fit(\n",
    "  train_ds,\n",
    "  validation_data= val_ds,\n",
    "  verbose = VERBOSE,\n",
    "  epochs = EPOCHS,\n",
    ")\n",
    "\n",
    "print(\"First model training time:\",time.time() - t0) # around 30 secs per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "gen_hist = gen_model.fit(\n",
    "  train_gen_ds,\n",
    "  validation_data= val_gen_ds,\n",
    "  verbose = VERBOSE,\n",
    "  epochs = round(EPOCHS),\n",
    ")\n",
    "print(\"Second model training time:\",time.time() - t0) # around 120 secs per epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "pre_hist = pre_model.fit(\n",
    "  train_ds,\n",
    "  validation_data= val_ds,\n",
    "  verbose = VERBOSE,\n",
    "  epochs = round(EPOCHS),\n",
    ")\n",
    "print(\"Third model training time:\",time.time() - t0) # around 140 secs per epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "pre_gen_hist = pre_gen_model.fit(\n",
    "  train_gen_ds,\n",
    "  validation_data= val_gen_ds,\n",
    "  verbose = VERBOSE,\n",
    "  epochs = round(EPOCHS),\n",
    ")\n",
    "print(\"Fourth model training time:\",time.time() - t0) # around 240 secs per epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "from matplotlib.pyplot import figure, subplot, plot, title, ylim, legend, grid\n",
    "\n",
    "x_axis = np.arange(len(hist.history['loss'])) + 1\n",
    "\n",
    "\n",
    "figure(figsize(13,5))\n",
    "subplot(1,2,1)\n",
    "plot(x_axis, hist.history['loss'], 'x-', label = 'training')\n",
    "plot(x_axis, hist.history['val_loss'], 'o-', label = 'validation')\n",
    "plot(x_axis, gen_hist.history['loss'], 'x-', label = 'gen training')\n",
    "plot(x_axis, gen_hist.history['val_loss'], '+-', label = 'gen validation')\n",
    "title('loss')\n",
    "ylim(0,)\n",
    "legend()\n",
    "grid()\n",
    "\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(x_axis, hist.history['accuracy'], 'x-', label = 'training')\n",
    "plot(x_axis, hist.history['val_accuracy'], 'o-', label = 'validation')\n",
    "plot(x_axis, gen_hist.history['accuracy'], '*-', label = 'gen training')\n",
    "plot(x_axis, gen_hist.history['val_accuracy'], '+-', label = 'gen validation')\n",
    "title('accuracy')\n",
    "ylim(0,1.0)\n",
    "legend()\n",
    "grid()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_axis = np.arange(len(hist.history['loss'])) + 1\n",
    "\n",
    "figure(figsize(13,5))\n",
    "subplot(1,2,1)\n",
    "plot(x_axis, pre_hist.history['loss'], 'x-', label = 'pre training')\n",
    "plot(x_axis, pre_hist.history['val_loss'], 'o-', label = 'pre validation')\n",
    "plot(x_axis, pre_gen_hist.history['loss'], 'x-', label = 'pre gen training')\n",
    "plot(x_axis, pre_gen_hist.history['val_loss'], '+-', label = 'pre gen validation')\n",
    "title('loss')\n",
    "ylim(0,)\n",
    "legend()\n",
    "grid()\n",
    "\n",
    "\n",
    "subplot(1,2,2)\n",
    "plot(x_axis, pre_hist.history['accuracy'], 'x-', label = 'pre raining')\n",
    "plot(x_axis, pre_hist.history['val_accuracy'], 'o-', label = 'pre validation')\n",
    "plot(x_axis, pre_gen_hist.history['accuracy'], '*-', label = 'pre gen training')\n",
    "plot(x_axis, pre_gen_hist.history['val_accuracy'], '+-', label = 'pre gen validation')\n",
    "title('accuracy')\n",
    "ylim(0,1.0)\n",
    "legend()\n",
    "grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Train Loss = \", 100 * (hist.history['val_loss'][EPOCHS - 1]), \"%\")\n",
    "print(\"Train Accuracy = \", 100 * (hist.history['val_accuracy'][EPOCHS -1]),\"%\")\n",
    "\n",
    "print(\"\\nGenerated data Train Loss = \", 100 * (gen_hist.history['val_loss'][EPOCHS -1]), \"%\")\n",
    "print(\"Generated data Train Accuracy = \", 100 * (gen_hist.history['val_accuracy'][EPOCHS -1]),\"%\")\n",
    "\n",
    "print(\"\\nPretrained model Train Loss = \", 100 * (pre_hist.history['val_loss'][EPOCHS - 1]), \"%\")\n",
    "print(\"Pretrained model Train Accuracy = \", 100 * (pre_hist.history['val_accuracy'][EPOCHS -1]),\"%\")\n",
    "\n",
    "print(\"\\nGenerated data Train Loss = \", 100 * (gen_hist.history['val_loss'][EPOCHS -1]), \"%\")\n",
    "print(\"Generated data Train Accuracy = \", 100 * (gen_hist.history['val_accuracy'][EPOCHS -1]),\"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results = model.evaluate(test_ds,verbose=VERBOSE)\n",
    "print(\"Model 1 test acc:\", 100 * results[1])\n",
    "\n",
    "results = gen_model.evaluate(test_ds,verbose=VERBOSE)\n",
    "print(\"Model 2 test acc:\", 100 * results[1])\n",
    "\n",
    "results = pre_model.evaluate(test_ds,verbose=VERBOSE)\n",
    "print(\"Model 3 test acc:\", 100 * results[1])\n",
    "\n",
    "results = pre_gen_model.evaluate(test_ds,verbose=VERBOSE)\n",
    "print(\"Model 4 test acc:\", 100 * results[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We used transfer method for this model. We tried to find pretrained model that worked best with our usecase. With first a google search what are the best pretrained models for our case we got a list of ones that are commonly used. We started testing the ones on that list to find out what is the best model for us. With all we used Imagenet as weights and had a very simple and few layer child model. First we tried some from the resnet family. ResNet50 and ResNet101 gave us similiar results but ResNet50 was alot faster. After that we tried VGG16 and VGG19. Those models werent too good for our case and gave us worst results compared to ResNets and also took little longer. They also require more memory  and are alot bigger sized models. Lastly we tried Inception family models. InceptionV3 and InceptionResNetV2 were our choises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}